# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eeCwvm4G11BqKAQWRRdrzcCs8Ckil2CD
"""

from flask import Flask, request, send_file
import json
import re
import faiss
from sentence_transformers import SentenceTransformer
import zipfile
import os
import tempfile

app = Flask(__name__)

# Load the model once when the app starts
model = SentenceTransformer('all-MiniLM-L6-v2')

def extract_chunks(json_data):
    """Extract text from OCR JSON and separate into labeled chunks."""
    text_entries = json_data['extracted_text']

    # Sort by y1 (top coordinate)
    text_entries.sort(key=lambda x: x['boundingBox'][1])

    # Group into lines (threshold: 30 pixels)
    lines = []
    current_line = [text_entries[0]]
    for entry in text_entries[1:]:
        if entry['boundingBox'][1] - current_line[-1]['boundingBox'][1] < 30:
            current_line.append(entry)
        else:
            current_line.sort(key=lambda x: x['boundingBox'][0])
            lines.append(current_line)
            current_line = [entry]
    if current_line:
        current_line.sort(key=lambda x: x['boundingBox'][0])
        lines.append(current_line)

    # Concatenate text within lines
    line_texts = [' '.join([entry['text'] for entry in line]) for line in lines]

    # Group into chunks based on labels
    label_pattern = r"^\d+\.\s*[A-Z]?\)"
    chunks = {}
    current_label = None
    current_chunk = []

    for line in line_texts:
        match = re.match(label_pattern, line)
        if match:
            if current_label is not None:
                chunks[current_label] = ' '.join(current_chunk)
            current_label = match.group(0)
            current_chunk = [line[len(current_label):].strip()]
        else:
            current_chunk.append(line)

    if current_label is not None:
        chunks[current_label] = ' '.join(current_chunk)

    return chunks

@app.route('/process', methods=['POST'])
def process_json():
    # Validate file upload
    if 'file' not in request.files:
        return 'No file uploaded', 400
    file = request.files['file']
    if file.filename == '':
        return 'No file selected', 400
    if not file.filename.endswith('.json'):
        return 'File must be a JSON file', 400

    try:
        # Use a temporary directory for all file operations
        with tempfile.TemporaryDirectory() as temp_dir:
            # Save the uploaded JSON file
            json_path = os.path.join(temp_dir, 'input.json')
            file.save(json_path)

            # Load JSON data
            with open(json_path, 'r') as f:
                data = json.load(f)

            # Extract chunks
            chunks = extract_chunks(data)

            # Generate embeddings
            labels = list(chunks.keys())
            chunk_texts = list(chunks.values())
            embeddings = model.encode(chunk_texts)

            # Create FAISS index
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings)

            # Save FAISS index and chunks to files
            faiss_file = os.path.join(temp_dir, 'faiss_index.bin')
            chunks_file = os.path.join(temp_dir, 'chunks.json')
            faiss.write_index(index, faiss_file)
            with open(chunks_file, 'w') as f:
                json.dump({'labels': labels, 'chunks': chunk_texts}, f)

            # Create a zip file containing both outputs
            zip_path = os.path.join(temp_dir, 'output.zip')
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                zipf.write(faiss_file, 'faiss_index.bin')
                zipf.write(chunks_file, 'chunks.json')

            # Send the zip file as the response
            return send_file(zip_path, as_attachment=True, download_name='output.zip')

    except Exception as e:
        return f'Error processing file: {str(e)}', 500

if __name__ == '__main__':
    app.run(debug=True)